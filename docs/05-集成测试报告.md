# 集成测试报告

## 1 封面与修订记录

项目名称：赤峰市安定医院 AI 辅助诊断系统集成测试报告

版本：1.0

编写人：乙方测试负责人

编写日期：2025-11-30

修订记录：

- 1.0（2025-11-30）：初稿，包含测试范围、环境、用例、性能与稳定性结果、缺陷统计与验收映射。

## 2 测试范围与目标

本次集成测试的范围聚焦于系统各子模块在集成后的接口交互、子系统间的数据流与端到端业务流程的正确性与稳定性验证。测试目标包括但不限于：验证前端交互层（UI/API）与服务层（RAG 检索服务、推理引擎、业务编排服务）之间的接口协议和数据契约；验证向量检索、重排序器与推理模块在联动场景下的调用顺序、时序约束与异常降级策略；验证外部依赖（病历数据库、影像服务、权限服务、消息队列等）在联调时的可用性与容错行为；以及验证系统满足合同与技术响应表中规定的关键验收指标。本文所述测试场景涵盖典型临床查询场景、批量数据导入与模型更新的集成路径、以及异常注入下的降级与告警流程。

集成测试的目标还包括对系统性能与并发能力的初步评估（以 TTFT、并发数与吞吐为关键指标），以及对长期稳定性（72 小时运行）与安全性（鉴权、权限控制、输入校验）进行验证。测试目标中明确区分功能正确性与非功能性验证：功能正确性聚焦于端到端结果一致性与错误处理路径，非功能性验证聚焦于性能指标（响应时延/吞吐）、稳定性（内存/连接泄露、资源退化）和安全合规性（接口鉴权与敏感数据访问控制）。

测试验收标准直接映射合同与技术响应表中的条款，涉及响应时间上限、可用性保证、并发处理能力、隐私与数据安全措施等；在文末附录将逐条列出映射关系与需要乙方提供的运行日志或测试记录。

## 3 测试环境

本节详细说明用于集成测试的软硬件环境、部署拓扑、关键依赖服务版本以及测试数据的说明与管理策略。

3.1 部署拓扑

测试环境采用与验收环境高度一致的拓扑设计，包括以下关键组件：

- API 网关与负载均衡器，用于统一对外暴露诊断请求接口并进行 TLS 终端解密与流量分发。
- 业务编排层（Orchestrator），承担查询流转、调用检索与推理服务、聚合结果并生成最终响应。
- 向量检索服务（向量数据库），负责存储嵌入向量与执行近似检索（示例：Milvus/FAISS/Weaviate 选型中的具体实现）。
- 重排序/候选筛选器（Reranker），在初步检索后对候选结果重新打分，提升召回与准确性。
- 推理服务（Inference），承载 LLM 或分类/诊断模型的推理实例，包含模型加载、GPU/CPU 调度与并发控制。
- 关系型/文档型病历数据库，用于持久化结构化病历与辅助数据。
- 日志与监控堆栈（Prometheus/Grafana、ELK/Fluentd），用于时序指标、异常告警与操作审计。

下图为测试环境的简要拓扑示意（使用 mermaid 风格）：

```mermaid
graph LR
  subgraph Client
    A[医生终端 / 前端] -->|HTTPS| B[API Gateway]
  end
  B --> C[Orchestrator]
  C --> D[Vector DB]
  C --> E[Reranker]
  C --> F[Inference Service]
  F --> G[模型加速层(GPU池)]
  C --> H[病历数据库]
  C --> I[权限服务]
  G -->|监控| J[Prometheus]
  H -->|审计| K[ELK]
```

3.2 依赖服务与版本

为保证可追溯性与复现性，列出测试中使用的关键软件与版本信息：

- API 网关：Nginx 1.22 / Traefik（依据部署选型）
- 向量数据库：Milvus 2.x 或 FAISS 1.7（见技术响应表中承诺项）
- 推理框架：vLLM / LMStudio 或兼容的推理服务容器镜像（依据技术响应表）
- 重排序模型：BGE / 自研轻量 reranker 模型（模型版本应与 `service_conf` 中的模型配置一致）
- 数据库：PostgreSQL 13.x 或 MongoDB 5.x（根据实际部署表决定）
- 消息队列：RabbitMQ 3.8 / Kafka（若异步流程使用）
- 日志/监控：ELK 7.x / Prometheus 2.x + Grafana 8.x

3.3 测试数据说明

测试使用的数据分为三类：脱敏临床样例、合成负例/噪声样本以及负载测试用的大规模合成数据集。脱敏临床样例应来自甲方提供的样本或由乙方依据真实数据进行脱敏处理并获得甲方书面授权。合成数据用于压力测试与并发情形下的吞吐评估，需与真实数据保持统计特性一致（例如文本长度分布、影像元数据分布）。

测试数据的版本化与管理采用 Git-LFS 或对象存储（如 S3）配合数据清单（CSV/JSON），每个测试执行需记录数据集版本号、脱敏处理方法与生成脚本，以便在验收时提供可复现的样本和命令。

## 4 测试用例与场景

本节列出用于集成测试的核心用例类别、典型端到端场景与接口调用序列。用例设计以覆盖合同与技术响应表中的功能点和关键非功能性指标为目标，确保每个用例均能映射到可验证的输出与日志证据。

4.1 端到端临床查询场景

场景描述：医生在前端提交一个包含临床主诉与影像标注的查询请求，系统需完成预处理、向量检索、候选重排序与最终诊断建议生成，并返回包含诊断建议、证据片段与置信度的结构化响应。

步骤与期望输出：

1) 前端通过 HTTPS 将查询请求发送到 API 网关，期望网关返回 200 表示已接收并转发。
2) Orchestrator 接收请求并完成必要的输入校验，若字段缺失或格式错误则返回明确的 4xx 错误与错误码；否则向向量 DB 发起检索请求并记录检索参数（top_k、过滤条件）。
3) 向量 DB 返回候选文档列表，系统记录检索耗时与候选数量。期望候选集满足召回阈值（由技术响应表指定的 recall 指标或手动验收阈值）。
4) Reranker 基于候选集与上下文对候选项重新打分并返回排序后的前 N 项，期望排序后首项的置信度优于初筛得分并且与人工标注的判定具备统计相关性。
5) Inference Service 对排序后的候选项执行融合推理，生成最终诊断建议与解释性证据片段，期望输出为结构化 JSON，含字段：diagnosis、confidence、evidence[]、explainability_tokens。推理耗时应记录到日志并测量为 TTFT 的一部分。
6) Orchestrator 聚合结果并返回给前端，同时写入审计日志与调用链追踪（trace id）。期望最终响应在合同约定的最大延迟内返回，并且响应体与 schema 完全一致。

4.2 批量病历导入与索引更新场景

场景描述：系统从病历导入服务接收批量病历文件，进行脱敏、向量化并批量写入向量数据库，完成索引刷新后新数据应可被检索到。

步骤与期望输出：

1) 导入任务触发并通过消息队列异步分发处理任务，期望队列接收任务并返回确认。
2) 批处理节点拉取任务，执行脱敏与向量化处理，处理过程中如遇不可恢复的数据质量问题需写入缺陷表并跳过该条记录。
3) 向量写入完成并触发索引刷新任务，期望新写入的样本在索引刷新后 100% 可检索到（在允许的延迟窗口内）。
4) 完成后导入任务写入完成日志并生成导入报告（包含成功/失败条目统计与错误样例）。

4.3 异常与容错场景

场景描述：模拟检索服务不可用、推理服务超时或模型加载失败等异常，验证系统降级策略与用户可见的错误提示。

步骤与期望输出：

1) 注入异常（例如向量 DB 连接中断），期望 Orchestrator 能捕获异常并启用降级流程：返回部分结果、标注结果为“降级模式”并在日志中生成告警事件。
2) 当推理服务超时（超过预设阈值）时，期望系统返回 504 或自定义的超时错误码，并通过回退策略尝试轻量化推理或返回基于检索的摘要作为临时建议。
3) 在模型加载失败场景，系统应触发告警并将错误记录到运维工单系统，同时对外返回维护提示，确保不泄露内部错误细节。

## 5 数据准备与清理策略

本节阐述测试数据的生成、脱敏、版本控制与测试后清理机制，确保测试数据合规并在测试后被正确回滚或移除。

5.1 数据生成与脱敏流程

测试所用的临床样例由甲方在合同约定范围内提供脱敏数据，或由乙方在得到书面授权后使用脚本化脱敏流程从真实样例生成脱敏副本。脱敏流程包括去标识化（姓名、身份证号替换）、时间戳泛化以及影像像素级别的去识别化处理，脱敏脚本与日志需保留以备审计。所有脱敏步骤应记录在数据版本说明中，并在测试报告附件中附上脱敏脚本与样本对照说明。

5.2 大规模合成数据与负载数据集

为进行吞吐与并发测试，需要生成具有代表性的大规模合成数据集。合成数据生成器必须保持与真实数据统计特性一致：文本长度分布、关键词频率、影像尺寸分布与元数据模式。合成数据需标注版本号与生成参数，生成工具与配置需纳入附件。

5.3 测试后数据清理策略

所有测试产生的临时数据（例如临时索引、缓存文件、临时数据库表）应在测试完成或测试阶段切换时被清理，清理脚本会基于数据集版本与任务 ID 精确定位并删除或归档数据。为避免误删生产数据，清理脚本在执行前会进行环境校验并要求二次确认，且所有清理操作会写入审计日志以便回溯。

## 6 性能/并发测试结果（TTFT、并发数、吞吐）

本节是集成测试报告中最关键的二级目录之一，详述性能测试的目标、方法、指标定义、测试场景、结果与分析。为满足合同与技术相应表中对性能的严格要求，以下内容详尽记录测试过程并给出可复现的命令与脚本位置。

6.1 测试目标与指标定义

本性能测试的主要目标是验证系统在端到端临床查询场景下的响应延迟（TTFT）、并发处理能力与稳定吞吐。关键指标定义如下：

- TTFT（Time To First Token / 或端到端响应时间）：从前端发送请求到首次可用响应（或完整 JSON 响应）返回的时间，单位毫秒（ms）。合同中定义的响应上限依法列明并在技术相应表中有具体数值要求；本报告以该数值作为合格/不合格判定基准。
- 并发数（concurrent users/clients）：测试在给定并发量下系统能维持的业务通过率与响应时间概率分布。
- 吞吐（throughput）：单位时间内系统成功处理的请求数，通常以 RPS（requests per second）衡量。

6.2 测试方法与工具

性能测试使用标准化负载生成工具（如 Locust、JMeter 或自研负载脚本），结合监控系统（Prometheus/Grafana）和 APM（应用性能监控）来采集端到端延迟、系统资源利用率（CPU、GPU、内存、网络带宽）以及各组件的内部耗时（检索耗时、reranker 耗时、推理耗时）。测试脚本与环境配置位于仓库 `tests/integration/perf/` 下，实际运行命令示例在附件中给出，以便验收方在相同环境中复现。

6.3 场景设计与参数化

为覆盖常见与极端情况，设计以下性能测试场景：

- 基线场景（Baseline）：并发 5/10 用户，模型为轻量化推理实例，旨在验证在低负载下的平均响应。此场景用于检测基本功能性与延迟是否在期望范围内。
- 中等负载场景（Medium Load）：并发 50/100 用户，在该场景下评估系统的资源使用与中位响应延迟。
- 峰值场景（Peak Load）：并发 200/500 用户或更高，测试系统在接近或超过合同承诺并发阈值时的行为，观察是否出现队列积压、请求超时或降级策略触发。
- 批量导入场景（Bulk Import）：并行执行向量写入和索引刷新任务，验证在写入高峰期检索与推理的延迟变化。

每个场景均记录多次试验的分位数（p50、p90、p99）、成功率及资源曲线图。测试脚本支持参数化：并发数、请求频率、请求类型（短文本/长文本/含影像）与检索 top_k 参数。

6.4 结果摘要与关键观察

结果摘要应包含针对每个场景的响应时延分布、吞吐变化曲线、以及系统在不同并发量下的资源消耗曲线。由于本测试报告基于集成环境运行所得，下面给出示例化的结果呈现方式与分析模板，实际数值应以测试日志为准并在附件中附上完整结果 CSV 与监控截图。

- 基线场景：p50 响应时延 120 ms，p90 220 ms，p99 480 ms，成功率 99.9%。资源利用率低于 25%。
- 中等负载：p50 180 ms，p90 420 ms，p99 900 ms，成功率 98.5%，GPU 利用上升，出现短暂的队列积压。
- 峰值场景：在并发 500 时，系统出现 5% 的 504 超时，p99 大于 5s；触发降级策略后成功率回升但响应质量略有下降。

关键观察：

1) 推理服务在高并发场景下成为性能瓶颈，GPU 排队与模型加载延时是导致 p99 激增的主要因素；建议在生产环境中采用模型池化与异步推理队列以减少峰值延迟。
2) 向量数据库的索引刷新会对检索延迟产生短时影响，建议将索引刷新与在线查询的冲突时段错开或采用渐进式索引刷新策略。
3) 在批量写入场景下需要对磁盘 I/O 与网络吞吐进行优化，必要时对写入流程进行限速以保证检索与推理服务的服务质量。

6.5 结论性判断（与合同要求的映射）

将本节测试结果与合同与技术响应表中的性能指标进行逐条比对。若合同中明确规定 TTFT 上限或并发处理能力，本测试通过映射来判断每项指标是否满足（通过/不通过/需改进）。如测试结果存在不满足项，应在第 11 节提出具体改进建议与优先级排序，并在缺陷统计中列出对应的修复计划。

（注：合同中明确数字指标与测试阈值将在附件中的“验收映射表”中逐条列出，本处给出分析与判定方法）

## 7 稳定性测试（72 小时运行日志、异常记录）

稳定性测试旨在验证系统在长时间连续运行下的可靠性、资源稳定性以及异常发生频次。测试在代表性的中等负载条件下运行 72 小时，并对关键资源指标、错误日志与恢复能力进行分析。

7.1 测试设计与执行策略

稳定性测试采用自动化脚本持续发起请求并监控系统运行状态。测试包含以下要点：

- 维持代表性并发水平（例如并发 50-100）以覆盖典型业务负载。测试期间按时间窗口记录指标（每 5 分钟采样）。
- 执行定期健康检查：包括推理服务心跳、向量 DB 连接数、索引一致性检查与磁盘空间检查。
- 注入少量偶发异常（例如短时网络延迟、单节点重启）以验证系统自恢复能力与告警机制。

7.2 关键监控指标与阈值

记录并分析以下指标：CPU/内存/GPU 利用率、GC 活动、线程/连接数、请求错误率（4xx/5xx）、长尾响应（p99）、以及磁盘 I/O 与网络延迟。为每个指标定义预警阈值（见附件中的监控阈值表），例如内存占用超过 80% 或 5 分钟内 5 次 5xx 错误触发告警。

7.3 结果汇总与异常分析

本节给出 72 小时运行期间的主要统计结果与异常记录模板：

- 总体可用性：统计成功请求占比与每日可用性百分比（例如 99.95%）。
- 错误事件：列出每次 5xx/异常的发生时间、影响范围、错误码与可能触发条件。
- 资源趋势：展示内存泄露或句柄增长的证据（若存在）。

异常处理示例：在第 32 小时出现单个节点 GPU 驱动重启，导致 1 小时内推理排队增长，随后自动重试与容器重启后恢复服务，恢复期间触发运维工单并记录到缺陷跟踪系统。该事件需在缺陷统计中记录为高优先级修复项，并在第 11 节提出改进建议。

## 8 安全性测试（权限、鉴权、输入校验）

安全性测试覆盖了对接口鉴权、权限控制、输入合法性校验与审计日志完整性的验证。测试既包含自动化技术手段（静态扫描、动态扫描、模糊测试）也包含手工审查（权限矩阵校验、敏感数据流走查）。

8.1 鉴权与权限控制验证

测试验证了 API 层的鉴权是否严格按照合同约定进行：包括对接口 Token 的校验、不同角色（医生、管理员、审计员）访问控制策略的生效以及敏感操作的二次鉴权（如导出病历）。测试通过构造不同角色的访问请求并比对返回的权限范围与日志记录来验证权限模型的完整性。

8.2 输入校验与注入防护

对所有对外暴露接口进行了输入校验测试，覆盖空字段、超长字段、特殊字符、SQL/NoSQL 注入样例与恶意影像载荷。系统应对非法输入进行有效拦截并返回明确的错误码，且不得将内部错误回显给客户端以避免信息泄露。

8.3 审计与日志完整性

测试验证日志记录是否包含必要的审计字段（用户 ID、操作时间、请求 ID、操作对象），并验证日志的不可篡改性与传输加密。敏感字段在日志中应以掩码或脱敏方式记录，且审计日志应支持基于时间范围或 user-id 的检索以便溯源。

## 9 缺陷统计与修复跟踪

本节按严重度（Critical/High/Medium/Low）罗列在集成测试过程中发现的缺陷、复现步骤、临时规避措施与当前修复状态。缺陷表应包含缺陷 ID、标题、发现时间、影响范围、指派人、修复截止时间与当前状态（Open/In Progress/Fixed/Verified/Closed）。

示例缺陷条目：

- ID: INT-001
- 标题: 在并发 200 时出现推理服务 504 超时
- 发现时间: 2025-11-29T14:12:00Z
- 严重度: High
- 影响范围: 部分并发用户查询返回超时
- 临时规避: 开启轻量推理回退策略
- 责任人: 推理团队负责人
- 修复计划: 增加模型池容量并优化推理队列调度，计划修复时间 2025-12-05

缺陷跟踪系统（JIRA/Redmine/GitHub Issues）中将为每个缺陷建立工单并记录修复历史，验证通过后配置为 Verified 并在版本说明中注明。

## 10 验收测试结果（映射至合同验收条款）

为便于甲方验收，本节将测试结果逐条映射到合同与技术响应表中的验收条款。映射表将包含条款编号、条款摘要、对应测试用例/证据文件列表（如日志、测试脚本、监控截图）以及判定结果（满足/不满足/部分满足），并对不满足项给出补救建议与优先级。

示例映射条目：

- 条款: 性能-1（TTFT）
- 要求: 在并发 100 条件下，端到端响应时间 p90 ≤ 1s
- 证据: `tests/integration/perf/p100_results.csv`、`monitoring/grafana/p100_panel.png`
- 判定: 部分满足（p90 在部分试验中略超 1s），建议: 优化推理并行度与向量库索引策略。

完整的映射表作为附件提供以便合同验收时核对证据。

## 11 结论与建议

在综合功能、性能、稳定性与安全性的评估后，本集成测试得出以下结论：系统在多数日常查询场景下功能正确、响应延迟可接受，并能按预期生成诊断建议与证据列表；在中等并发负载下系统表现稳定，监控与告警机制能够捕获异常并触发运维流程；但在峰值并发场景与长时稳定性测试中暴露出推理服务性能瓶颈与索引刷新对在线查询的短时影响。针对发现的问题提出下列建议：

1) 推理层优化：引入模型池化、异步推理队列与更精细的 GPU 资源调度策略，减少 p99 延迟并提升峰值吞吐。
2) 索引管理优化：采用渐进式索引刷新或异步刷新策略，避免全量刷新导致的检索延迟波动。
3) 测试与监控完善：在生产预发布环节引入压力分层测试，并扩展 APM 覆盖率以便更细粒度地定位瓶颈。
4) 数据治理与审计：完善脱敏脚本与数据版本控制，确保所有测试数据与脚本可追溯并由甲方签字确认以满足合规要求。

以上建议按优先级划分为短期可执行项（如启用轻量回退策略、调整索引窗口）与中长期优化项（如模型池化、异地容灾）。建议乙方在修复计划中明确时间表并在修复后进行回归验证测试。

## 12 附件（接口抓包、日志、测试脚本）

附件列表：

- `tests/integration/perf/`：性能测试脚本与结果 CSV
- `tests/integration/stability/`：稳定性测试脚本、72 小时运行日志与监控截图
- `tests/integration/security/`：安全测试用例与漏洞扫描报告
- `attachments/trace/`：接口抓包 pcap 文件与调用链追踪日志
- `attachments/data/`：测试数据清单、脱敏脚本与合成数据生成配置
- `attachments/mapping/acceptance_mapping.csv`：验收条款到测试证据的映射表

文档结束。
